---
layout: page
title: Weekly Summaries
permalink: /jcsummary/
---

## Spring 2024

### Week 2

Instructions are [here](/jcweek2/).

Simulated datasets using SeqGen with different scaling factors and recorded whether PAUP exhaustive ML search returned true tree. The contents of the file _tree.txt_ was 

    (A:1.0,B:1.0,((C:1.0,D:1.0):1.0,(E:1.0,F:1.0):1.0):1.0) 

and the SeqGen command was:

    seq-gen -mHKY -l10000 -n1 -p1 -t2.0 -on -s1.0 < tree.txt > simdata.nex

Here is a possible result (failed to save actual results).

| scaler  | result | 
| :-----: | :----: |
| 1000.0  |   no   |
| 100.00  |   yes  |
| 10.000  |   yes  |
| 1.0000  |   yes  |
| 0.1000  |   yes  |
| 0.0100  |   yes  |
| 0.0010  |   yes  |
| 0.0001  |   no   |

### Week 3,4

Instructions are [here](/jcweek3/).

Simulated 4 datasets using SeqGen as follows:

    seq-gen -mHKY -l10000 -n1 -p1 -t0.5 -on -s0.00001 < tree.txt > slow.nex
    seq-gen -mHKY -l10000 -n1 -p1 -t0.5 -on -s0.01    < tree.txt > medium.nex
    seq-gen -mHKY -l10000 -n1 -p1 -t0.5 -on -s1.0     < tree.txt > fast.nex
    seq-gen -mHKY -l500   -n1 -p1 -t0.5 -on -s1.0     < tree.txt > fast500.nex

Ran RevBayes on all of these using the instructions at https://plewis.github.io/revbayes/

Medium should have given the highest marginal clade posteriors, with others being less confident because of lower information content. Again, didn't save the results.

### Week 5

Instructions are [here](/jcweek5/).

Used Galax to estimate information content in the simulated data sets. Paul provided both Galax and a Python program (_rb2nxs.py_) that converts RevBayes tree files to NEXUS format tree files so that they can be input to Galax. For example,

    python3 rb2nxs.py medium_run_1.trees medium1.tre
    python3 rb2nxs.py medium_run_2.trees medium2.tre
    python3 rb2nxs.py medium_run_3.trees medium3.tre
    python3 rb2nxs.py medium_run_4.trees medium4.tre

A listfile named _medium-treefiles.txt_ was created that just contained the four NEXUS tree files from one RevBayes run:

    medium1.tre
    medium2.tre
    medium3.tre
    medium4.tre

and galax was run as follows:

    galax --listfile medium-treefiles.txt --skip 1 --outfile medium-output

Here is a key to the columns of output generated by Galax:

| Header | Description                                 |
| :----- | :------------------------------------------ |
|   H    | prior entropy = log(N)                      |
|   H*   | posterior entropy (max = 0.0, min = H)      |
|   I    | information = H - H*                        |
|   Ipct | I as a percentage                           |
|   D    | dissonance (only reported if multiple runs) |
|   Dpct | dissonance as a percentage                  |

Medium should have the most information according to galax, but actual results not saved.

### Week 6

Instructions are [here](/jcweek6/).

Paul provided the Python program _bdtree.py_ that generates a random tree with 6 taxa (stored in _tree.txt_) and a SeqGen script (_sg.sh_). Simulations were performed with `s0.0001` so that there would be low information. Ran RevBayes for 10,000 generations saving every generation. The 4 runs together provide 40,000 samples, which is enough to visit each of the 105 possible tree topologies about 380 times.

Run _rb2nxs.py_ and _galax_ like this to combine independent RevBayes runs:

    python3 rb2nxs.py "test_run_*.trees" test.tre
    galax --treefile test.tre --outfile test-output
    
Running _rb2nxs.py_ like this saves only 50% of the trees:

    python3 rb2nxs.py "test_run_*.trees" test50.tre  50
    
Reduced posterior sample to 50%, 10%, 5%, and 1%. Seems to be an error at the end of the file (945 should be 105 because RevBayes explores unrooted trees).

### Week 7

Instructions are [here](/jcweek7/).

Apparently some issues cropped up in week 6 so this week was a repeat with improved instructions. 

Added variables to the RevBayes script: `datafname`, `treefname`, `logfname`, `mapfname`, and `ignore_data`.

RevBayes instructed to ignore data.

Reduced posterior sample to 50%, 10%, 5%, 1%, 0.05%, and 0.01%. The estimate of information content should start deteriorating (e.g. Ipct > 5) at the smallest of these percentages.

### Week 8

Instructions are [here](/jcweek8/).

This week watch Paul's Evolution meeting address from 2016.

## Week 9

Instructions are [here](/jcweek9/).

This week's goal was to learn how to do array jobs on the cluster. Performed zeroinfo (RevBayes samples from the prior) and hasinfo (specified 0.001 scaler to bdtree2.py to keep information content low). Kept array jobs to just 5 replicates. Once we know everything is working, we can increase to 100s of jobs.

## Week 10

Instructions are [here](/jcweek10/).

Repeated array jobs with new, improved galax (but unclear now what modifications were made to galax). Also created a _summarize.py_ script to summarize results from all the simulation directories.

## Week 11 (April 8-12, 2024)

Instructions are [here](/jcweek11/).

Added dissonance estimation to the array job and read the original paper: [10.1093/sysbio/syw042](https://doi.org/10.1093/sysbio/syw042).

Expect dissonance to be pretty high when information is low and the sample size is much smaller than the number of possible trees.

## Week 12 (April 15-19, 2024)

Instructions are [here](/jcweek12/).

Started analyzing real data provided by ZM.

10000 iterations, sampled every iteration

|    dir  |  coverage  |        H |      H* |        I |     Ipct |    covH |  covIpct |  rawIpct |    Dpct |
| gene30  |   0.99183  | 46.84760 | 6.21007 | 40.63753 | 86.74410 |10.60484 | 41.44116 | 41.69115 | 0.05811 |
| gene26  |   0.91726  | 46.84760 | 7.35336 | 39.49424 | 84.30366 |10.68300 | 31.16764 | 32.67481 | 0.09793 |
| gene28  |   0.92953  | 46.84760 | 9.42355 | 37.42405 | 79.88466 |10.66971 | 11.67943 | 13.45773 | 0.09834 |
| gene34  |   0.99613  | 46.84760 | 5.91821 | 40.92939 | 87.36709 |10.60051 | 44.17053 | 44.26278 | 0.05799 |
| gene21  |   0.92512  | 46.84760 | 8.65577 | 38.19183 | 81.52356 |10.67447 | 18.91145 | 20.79908 | 0.15035 |
| gene32  |   0.98973  | 46.84760 | 5.66063 | 41.18697 | 87.91693 |10.60696 | 46.63286 | 46.85202 | 0.10671 |

## Week 13 (April 22-26, 2024)

Instructions are [here](/jcweek13/).

Same data, but longer runs and more thinning to see if dissonance between runs could be reduced.

100000 iterations, sampled every 10 iterations
 
|    dir | coverage |        H |      H* |        I |     Ipct |     covH  |  covIpct |  rawIpct  |    Dpct |
| gene30 |  0.99161 | 46.84760 | 6.21626 | 40.63134 | 86.73089 | 10.60506  | 41.38402 | 41.62684  | 0.05423 |
| gene26 |  0.91891 | 46.84760 | 7.33674 | 39.51086 | 84.33914 | 10.68120  | 31.31166 | 32.80386  | 0.07742 |
| gene28 |  0.93236 | 46.84760 | 9.41105 | 37.43655 | 79.91135 | 10.66667  | 11.77144 | 13.48282  | 0.07730 |
| gene34 |  0.99637 | 46.84760 | 5.93412 | 40.91348 | 87.33314 | 10.60027  | 44.01917 | 44.11821  | 0.03837 |
| gene21 |  0.92457 | 46.84760 | 8.67267 | 38.17493 | 81.48749 | 10.67506  | 18.75766 | 20.69148  | 0.09840 |
| gene32 |  0.99027 | 46.84760 | 5.63668 | 41.21092 | 87.96805 | 10.60641  | 46.85592 | 47.05958  | 0.07064 |

H  = prior entropy = log(no. unrooted trees for 20 taxa)
H* = posterior entropy

For `gene30`:
* covH    = 10.60506013 = ln(40000/.99161)
* raw prior entropy     = ln(40000) = 10.59663473
* raw posterior entropy = 6.18559
* rawIpct = 41.62684517 = 100.0*(ln(40000) - 6.18559)/ln(40000) 


## Fall 2024

## Week 14 (September 16-20, 2024)

Instructions are [here](/jcweek14/).

This week we began generating data that will be used in the paper. The first table we will need shows how information content estimation fails if the number of samples from the posterior does not greatly exceed the expected number of plausible tree topologies. Perform array jobs in which each of 20 tasks asks RevBayes to sample from the prior (zero info) for problems in which the number of taxa is 9 (`1*3*5*7*9*11*13 = 135,135` unrooted topologies). Each array job examines a different posterior sample size (10k, 100k, 1000k, 10000k) and we expect information to be accurately estimated (i.e. 0.0 information) only for the 1000k and 10000k cases.

Jessica had problems with the last case (10000k), which took 10 hours to run and ended up crashing before finishing. The problem was with the python script rb2nxs.py, which could not handle a file with 10 million lines. It turns out that galax can read revbayes tree files directly, so there was no need for rb2nxs.py anyway.

## Week 15 (September 30 to October 4, 2024)

We skipped a week because Analisa and I were at the ICERM workshop at Brown University on Thursday, Sept. 19.

Instructions are [here](/jcweek15/).

This week we will try the simulations for 10000k samples again using an updated version of galax that reads RevBayes tree files directly without requiring conversion to nexus format. It turns out that there was a bug in a regex specification in galax that was causing tree descriptions containing an `e` in a branch length specification (e.g. `:1.12345e-04`) to be skipped. That has been fixed, and the output for raw entropy now includes two different estimates, one in which the prior entropy is based on the number of samples and the other in which the prior entropy is based on the number of tree topologies.




